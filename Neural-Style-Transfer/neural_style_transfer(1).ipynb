{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive"
      ],
      "metadata": {
        "id": "FRrJjG01lswq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxAZ0E6wls8B",
        "outputId": "1ece5a92-bd17-4ace-e260-b0b4b61f2c97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting style and content images"
      ],
      "metadata": {
        "id": "-cw359bpl481"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_image_path = \"/content/drive/MyDrive/Colab Notebooks/Los-Angeles-downtown.jpg\"\n",
        "style_reference_image_path = \"/content/drive/MyDrive/Colab Notebooks/night1.jpg\""
      ],
      "metadata": {
        "id": "bMgMZpBwlxpX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_width, original_height = keras.utils.load_img(base_image_path).size\n",
        "\n",
        "img_height = 400\n",
        "img_width = round(original_width * img_height / original_height)"
      ],
      "metadata": {
        "id": "unXCpB0lnB-t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary Functions"
      ],
      "metadata": {
        "id": "RX4EMBf1nOme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "  img = keras.utils.load_img(image_path, target_size=(img_height, img_width))\n",
        "  img = keras.utils.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = keras.applications.vgg19.preprocess_input(img)\n",
        "  return img"
      ],
      "metadata": {
        "id": "TyQULkfvnSmX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deprocess_image(img):\n",
        "  img = img.reshape((img_height, img_width, 3))\n",
        "  img[:, :, 0] += 103.939\n",
        "  img[:, :, 1] += 116.779\n",
        "  img[:, :, 2] += 123.68\n",
        "  img = img[:, :, ::-1] # converts from BGR to RGB\n",
        "  img = np.clip(img, 0, 255).astype(\"uint8\")\n",
        "  return img"
      ],
      "metadata": {
        "id": "KnplQlBWna2g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using a pretrained VGG19 model to create a feature extractor**"
      ],
      "metadata": {
        "id": "kJhrPURB9QNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.applications.vgg19.VGG19(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GduCP1mS9RSv",
        "outputId": "f8a8148e-27ae-4b04-d493-37cf2119ff1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function\n",
        "\n",
        "- `Content Loss`:\n",
        "  L2 norm between the activations of an upper layer in a pretrained convnet, computed over the target image, and the activations of the same layer computed over the generated image"
      ],
      "metadata": {
        "id": "tIlDJU4yn2pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def content_loss(base_img, combination_img):\n",
        "  return tf.reduce_sum(tf.square(combination_img - base_img))"
      ],
      "metadata": {
        "id": "1V17SjMJnw3i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Style Loss`: Next is the style loss. It uses an auxiliary function to compute the Gram matrix of an\n",
        "input matrix: a map of the correlations found in the original feature matrix.\n",
        "\n",
        "\n",
        "![Screenshot from 05-12-23 17:47:41](https://github.com/surajkarki66/MediLeaf_backend/assets/50628520/37fb42b7-0f21-47cd-beaf-76393ed6d0ee)\n",
        "\n",
        "![Screenshot from 05-12-23 17:56:40](https://github.com/surajkarki66/MediLeaf_backend/assets/50628520/9e8fbdee-88f5-470e-af53-4a028ee4fb4f)\n"
      ],
      "metadata": {
        "id": "gDBZbYbuokIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_matrix(x):\n",
        "  x = tf.transpose(x, (2, 0, 1))\n",
        "  features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "  gram = tf.matmul(features, tf.transpose(features))\n",
        "  return gram"
      ],
      "metadata": {
        "id": "LalPZZa8ogRr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def style_loss(style_img, combination_img):\n",
        "  S = gram_matrix(style_img)\n",
        "  C = gram_matrix(combination_img)\n",
        "  channels = 3\n",
        "  size = img_height * img_width\n",
        "  return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ],
      "metadata": {
        "id": "UNIbDoWxo9tS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Total Variational Loss`: To these two loss components, you add a third: the total variation loss, which operates\n",
        "on the pixels of the generated combination image. It encourages spatial continuity in the generated image, thus avoiding overly pixelated results. You can interpret it as a regularization loss."
      ],
      "metadata": {
        "id": "gBeEmAKD7NbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def total_variation_loss(x):\n",
        "  a = tf.square(x[:, : img_height - 1, : img_width - 1, :] - x[:, 1:, : img_width - 1, :])\n",
        "  b = tf.square(x[:, : img_height - 1, : img_width - 1, :] - x[:, : img_height - 1, 1:, :])\n",
        "  return tf.reduce_sum(tf.pow(a + b, 1.25))"
      ],
      "metadata": {
        "id": "uG0if96q7TXp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss that you minimize is a weighted average of these three losses. To compute the content loss, you use only one upper layer—the block5_conv2 layer—whereas for the style loss, you use a list of layers that spans both low-level and high-level layers. You add the total variation loss at the end."
      ],
      "metadata": {
        "id": "RT8PSc0N7r49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending on the style-reference image and content image you’re using, you’ll likely want to tune the content_weight coefficient (the contribution of the content loss to the total loss). A higher content_weight means the target content will be more recognizable in the generated image."
      ],
      "metadata": {
        "id": "SaqivLMn79JI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers to use for the style loss\n",
        "style_layer_names = [\n",
        "  \"block1_conv1\",\n",
        "  \"block2_conv1\",\n",
        "  \"block3_conv1\",\n",
        "  \"block4_conv1\",\n",
        "  \"block5_conv1\",\n",
        "]\n",
        "\n",
        "# The layer to use for content loss\n",
        "content_layer_name = \"block5_conv2\"\n",
        "\n",
        "# Contribution weight of the total variation loss\n",
        "total_variation_weight = 1e-6\n",
        "\n",
        "# Contribution weight of the  style loss\n",
        "style_weight = 1e-6\n",
        "\n",
        "# Contribution weight of the  content loss\n",
        "content_weight = 2.5e-8"
      ],
      "metadata": {
        "id": "M6Vb_SgK7hBs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(combination_image, base_image, style_reference_image):\n",
        "    input_tensor = tf.concat(\n",
        "        [base_image, style_reference_image, combination_image], axis=0\n",
        "    )\n",
        "    features = feature_extractor(input_tensor)\n",
        "    loss = tf.zeros(shape=())\n",
        "    layer_features = features[content_layer_name]\n",
        "    base_image_features = layer_features[0, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    loss = loss + content_weight * content_loss(\n",
        "        base_image_features, combination_features\n",
        "    )\n",
        "    for layer_name in style_layer_names:\n",
        "        layer_features = features[layer_name]\n",
        "        style_reference_features = layer_features[1, :, :, :]\n",
        "        combination_features = layer_features[2, :, :, :]\n",
        "        style_loss_value = style_loss(\n",
        "          style_reference_features, combination_features)\n",
        "        loss += (style_weight / len(style_layer_names)) * style_loss_value\n",
        "\n",
        "    loss += total_variation_weight * total_variation_loss(combination_image)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "dAub4L8X81c5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up the gradient-descent process**"
      ],
      "metadata": {
        "id": "a0jANhdj9u0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def compute_loss_and_grads(combination_image, base_image, style_reference_image):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(combination_image, base_image, style_reference_image)\n",
        "    grads = tape.gradient(loss, combination_image)\n",
        "    return loss, grads\n",
        "\n",
        "optimizer = keras.optimizers.SGD(\n",
        "    keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96\n",
        "    )\n",
        ")\n",
        "\n",
        "base_image = preprocess_image(base_image_path)\n",
        "style_reference_image = preprocess_image(style_reference_image_path)\n",
        "combination_image = tf.Variable(preprocess_image(base_image_path))\n",
        "iterations = 10000\n",
        "for i in range(1, iterations + 1):\n",
        "    loss, grads = compute_loss_and_grads(\n",
        "        combination_image, base_image, style_reference_image\n",
        "    )\n",
        "    optimizer.apply_gradients([(grads, combination_image)])\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Iteration {i}: loss={loss:.2f}\")\n",
        "        img = deprocess_image(combination_image.numpy())\n",
        "        fname = f\"combination_image_at_iteration_{i}.png\"\n",
        "        keras.utils.save_img(fname, img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-1L6xjX9tEe",
        "outputId": "fcfa11d8-b375-420d-b84e-8d5ccfbe156c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100: loss=12281.91\n",
            "Iteration 200: loss=9658.75\n",
            "Iteration 300: loss=8654.45\n",
            "Iteration 400: loss=8104.18\n",
            "Iteration 500: loss=7746.04\n",
            "Iteration 600: loss=7489.56\n",
            "Iteration 700: loss=7295.59\n",
            "Iteration 800: loss=7142.16\n",
            "Iteration 900: loss=7016.88\n",
            "Iteration 1000: loss=6912.29\n",
            "Iteration 1100: loss=6823.41\n",
            "Iteration 1200: loss=6746.81\n",
            "Iteration 1300: loss=6680.04\n",
            "Iteration 1400: loss=6621.24\n",
            "Iteration 1500: loss=6568.90\n",
            "Iteration 1600: loss=6522.08\n",
            "Iteration 1700: loss=6479.89\n",
            "Iteration 1800: loss=6441.75\n",
            "Iteration 1900: loss=6407.10\n",
            "Iteration 2000: loss=6375.43\n",
            "Iteration 2100: loss=6346.39\n",
            "Iteration 2200: loss=6319.72\n",
            "Iteration 2300: loss=6295.10\n",
            "Iteration 2400: loss=6272.32\n",
            "Iteration 2500: loss=6251.19\n",
            "Iteration 2600: loss=6231.61\n",
            "Iteration 2700: loss=6213.39\n",
            "Iteration 2800: loss=6196.37\n",
            "Iteration 2900: loss=6180.46\n",
            "Iteration 3000: loss=6165.58\n",
            "Iteration 3100: loss=6151.68\n",
            "Iteration 3200: loss=6138.68\n",
            "Iteration 3300: loss=6126.50\n",
            "Iteration 3400: loss=6115.06\n",
            "Iteration 3500: loss=6104.31\n",
            "Iteration 3600: loss=6094.20\n",
            "Iteration 3700: loss=6084.68\n",
            "Iteration 3800: loss=6075.69\n",
            "Iteration 3900: loss=6067.19\n",
            "Iteration 4000: loss=6059.16\n",
            "Iteration 4100: loss=6051.56\n",
            "Iteration 4200: loss=6044.36\n",
            "Iteration 4300: loss=6037.57\n",
            "Iteration 4400: loss=6031.12\n",
            "Iteration 4500: loss=6025.03\n",
            "Iteration 4600: loss=6019.25\n",
            "Iteration 4700: loss=6013.75\n",
            "Iteration 4800: loss=6008.53\n",
            "Iteration 4900: loss=6003.58\n",
            "Iteration 5000: loss=5998.88\n",
            "Iteration 5100: loss=5994.42\n",
            "Iteration 5200: loss=5990.17\n",
            "Iteration 5300: loss=5986.12\n",
            "Iteration 5400: loss=5982.26\n",
            "Iteration 5500: loss=5978.59\n",
            "Iteration 5600: loss=5975.10\n",
            "Iteration 5700: loss=5971.76\n",
            "Iteration 5800: loss=5968.57\n",
            "Iteration 5900: loss=5965.54\n",
            "Iteration 6000: loss=5962.64\n",
            "Iteration 6100: loss=5959.88\n",
            "Iteration 6200: loss=5957.24\n",
            "Iteration 6300: loss=5954.72\n",
            "Iteration 6400: loss=5952.31\n",
            "Iteration 6500: loss=5950.01\n",
            "Iteration 6600: loss=5947.81\n",
            "Iteration 6700: loss=5945.71\n",
            "Iteration 6800: loss=5943.69\n",
            "Iteration 6900: loss=5941.77\n",
            "Iteration 7000: loss=5939.94\n",
            "Iteration 7100: loss=5938.18\n",
            "Iteration 7200: loss=5936.50\n",
            "Iteration 7300: loss=5934.90\n",
            "Iteration 7400: loss=5933.36\n",
            "Iteration 7500: loss=5931.89\n",
            "Iteration 7600: loss=5930.48\n",
            "Iteration 7700: loss=5929.12\n",
            "Iteration 7800: loss=5927.83\n",
            "Iteration 7900: loss=5926.60\n",
            "Iteration 8000: loss=5925.41\n",
            "Iteration 8100: loss=5924.28\n",
            "Iteration 8200: loss=5923.20\n",
            "Iteration 8300: loss=5922.16\n",
            "Iteration 8400: loss=5921.16\n",
            "Iteration 8500: loss=5920.21\n",
            "Iteration 8600: loss=5919.30\n",
            "Iteration 8700: loss=5918.42\n",
            "Iteration 8800: loss=5917.58\n",
            "Iteration 8900: loss=5916.78\n",
            "Iteration 9000: loss=5916.01\n",
            "Iteration 9100: loss=5915.27\n",
            "Iteration 9200: loss=5914.56\n",
            "Iteration 9300: loss=5913.88\n",
            "Iteration 9400: loss=5913.23\n",
            "Iteration 9500: loss=5912.61\n",
            "Iteration 9600: loss=5912.01\n",
            "Iteration 9700: loss=5911.44\n",
            "Iteration 9800: loss=5910.89\n",
            "Iteration 9900: loss=5910.36\n",
            "Iteration 10000: loss=5909.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "CnZyACKc9-T4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1103c51-b4ee-473e-bef0-ee684571fe88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combination_image_at_iteration_10000.png  combination_image_at_iteration_5500.png\n",
            "combination_image_at_iteration_1000.png   combination_image_at_iteration_5600.png\n",
            "combination_image_at_iteration_100.png\t  combination_image_at_iteration_5700.png\n",
            "combination_image_at_iteration_1100.png   combination_image_at_iteration_5800.png\n",
            "combination_image_at_iteration_1200.png   combination_image_at_iteration_5900.png\n",
            "combination_image_at_iteration_1300.png   combination_image_at_iteration_6000.png\n",
            "combination_image_at_iteration_1400.png   combination_image_at_iteration_600.png\n",
            "combination_image_at_iteration_1500.png   combination_image_at_iteration_6100.png\n",
            "combination_image_at_iteration_1600.png   combination_image_at_iteration_6200.png\n",
            "combination_image_at_iteration_1700.png   combination_image_at_iteration_6300.png\n",
            "combination_image_at_iteration_1800.png   combination_image_at_iteration_6400.png\n",
            "combination_image_at_iteration_1900.png   combination_image_at_iteration_6500.png\n",
            "combination_image_at_iteration_2000.png   combination_image_at_iteration_6600.png\n",
            "combination_image_at_iteration_200.png\t  combination_image_at_iteration_6700.png\n",
            "combination_image_at_iteration_2100.png   combination_image_at_iteration_6800.png\n",
            "combination_image_at_iteration_2200.png   combination_image_at_iteration_6900.png\n",
            "combination_image_at_iteration_2300.png   combination_image_at_iteration_7000.png\n",
            "combination_image_at_iteration_2400.png   combination_image_at_iteration_700.png\n",
            "combination_image_at_iteration_2500.png   combination_image_at_iteration_7100.png\n",
            "combination_image_at_iteration_2600.png   combination_image_at_iteration_7200.png\n",
            "combination_image_at_iteration_2700.png   combination_image_at_iteration_7300.png\n",
            "combination_image_at_iteration_2800.png   combination_image_at_iteration_7400.png\n",
            "combination_image_at_iteration_2900.png   combination_image_at_iteration_7500.png\n",
            "combination_image_at_iteration_3000.png   combination_image_at_iteration_7600.png\n",
            "combination_image_at_iteration_300.png\t  combination_image_at_iteration_7700.png\n",
            "combination_image_at_iteration_3100.png   combination_image_at_iteration_7800.png\n",
            "combination_image_at_iteration_3200.png   combination_image_at_iteration_7900.png\n",
            "combination_image_at_iteration_3300.png   combination_image_at_iteration_8000.png\n",
            "combination_image_at_iteration_3400.png   combination_image_at_iteration_800.png\n",
            "combination_image_at_iteration_3500.png   combination_image_at_iteration_8100.png\n",
            "combination_image_at_iteration_3600.png   combination_image_at_iteration_8200.png\n",
            "combination_image_at_iteration_3700.png   combination_image_at_iteration_8300.png\n",
            "combination_image_at_iteration_3800.png   combination_image_at_iteration_8400.png\n",
            "combination_image_at_iteration_3900.png   combination_image_at_iteration_8500.png\n",
            "combination_image_at_iteration_4000.png   combination_image_at_iteration_8600.png\n",
            "combination_image_at_iteration_400.png\t  combination_image_at_iteration_8700.png\n",
            "combination_image_at_iteration_4100.png   combination_image_at_iteration_8800.png\n",
            "combination_image_at_iteration_4200.png   combination_image_at_iteration_8900.png\n",
            "combination_image_at_iteration_4300.png   combination_image_at_iteration_9000.png\n",
            "combination_image_at_iteration_4400.png   combination_image_at_iteration_900.png\n",
            "combination_image_at_iteration_4500.png   combination_image_at_iteration_9100.png\n",
            "combination_image_at_iteration_4600.png   combination_image_at_iteration_9200.png\n",
            "combination_image_at_iteration_4700.png   combination_image_at_iteration_9300.png\n",
            "combination_image_at_iteration_4800.png   combination_image_at_iteration_9400.png\n",
            "combination_image_at_iteration_4900.png   combination_image_at_iteration_9500.png\n",
            "combination_image_at_iteration_5000.png   combination_image_at_iteration_9600.png\n",
            "combination_image_at_iteration_500.png\t  combination_image_at_iteration_9700.png\n",
            "combination_image_at_iteration_5100.png   combination_image_at_iteration_9800.png\n",
            "combination_image_at_iteration_5200.png   combination_image_at_iteration_9900.png\n",
            "combination_image_at_iteration_5300.png   drive\n",
            "combination_image_at_iteration_5400.png   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v66OZxQZKTO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}