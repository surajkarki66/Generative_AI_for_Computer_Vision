## GAN(Generative Adversarial Network)

#### Introduction

First GAN is created by Ian Goodfellow in 2014. It is a one of the famous generative model.
The Generative Adversarial Network (GAN) comprises of two models: a generative model G and a discriminative model D. The generative model can be considered as a counterfeiter who is trying to generate fake currency and use it without being caught, whereas the discriminative model is similar to police, trying to catch the fake currency. This competition goes on till the counterfeiter becomes smart enough to successfully fool the police.

It is called Adversarial because it is a competition between two components.

#### Generator:

It takes a sample data from input noise and generate a fake data exactly like real input data.
The generator model learns the joint probability distribution of the input variable and output variable.
It uses Naive Bayes .
`-> P(X, Y)`
`-> P(X|Y) P(Y)`
`-> P(Y|X) P(X)`

#### Discriminator:

It tries to predict whether the data generated by generator is real or fake.
The models learns conditional probability of the targeted variable given the input variable.
eg: Logistic Regression.
`-> P(Y|X=x)`

#### Lets define some parameter and variable

![1_No6f6hSCKaiXs2Mr9T9wpA](https://user-images.githubusercontent.com/50628520/90130639-8718db80-dd8a-11ea-81ed-1e4e0363c1af.png)

#### Structure of a GAN

![st](https://user-images.githubusercontent.com/50628520/90130850-dd861a00-dd8a-11ea-9d2b-3f1ed7e3dd88.jpg)

Here Discriminator try to maximize the chances of predicting classes.
But Generator try to fool Discriminator by producing data same as input data.

#### Loss Function:

![1_kACQPgX3Dk-X7u3J51JXxw](https://user-images.githubusercontent.com/50628520/90130948-07d7d780-dd8b-11ea-9301-8f5c92451ef4.png)

The loss function described in the original paper by Ian Goodfellow et al. can be derived from the formula of binary cross-entropy loss. The binary cross-entropy loss can be written as,

##### 1) Discriminator loss:

![1_brURhcYCI6WtbTuEw1XJ-Q](https://user-images.githubusercontent.com/50628520/90131095-47062880-dd8b-11ea-938e-523698240d8e.png)

Now, the objective of the discriminator is to correctly classify the fake and real dataset. For this, equations (1) and (2) should be maximized and final loss function for the discriminator can be given as,
![1_fWHhgZg_KNS3h8qq82QD3Q](https://user-images.githubusercontent.com/50628520/90131135-5be2bc00-dd8b-11ea-8c87-a53ef70fde51.png)

##### 2) Generator loss:

Here, the generator is competing against discriminator. So, it will try to minimize the equation (3) and loss function is given as

![1_Hdgo1Slf4fDiSrUfO3IwIQ](https://user-images.githubusercontent.com/50628520/90131385-c693f780-dd8b-11ea-9b25-c6495bfd2e1e.png)

##### 3) Combined loss function:

Combining eqn 3 and 4 we get.

![1__vFj5-pJP866w-LzdaHdoA](https://user-images.githubusercontent.com/50628520/90131458-e75c4d00-dd8b-11ea-86c2-df04ec7e493d.png)

Remember that the above loss function is valid only for a single data point, to consider entire dataset we need to take the expectation of the above equation as

![1_79sBUnY8G3nlV9khUr1jkg](https://user-images.githubusercontent.com/50628520/90131532-0529b200-dd8c-11ea-9340-5ee41b24b3b4.png)

#### Training Loop:

![p](https://user-images.githubusercontent.com/50628520/90131762-65205880-dd8c-11ea-8bb5-410dbe1e9e88.jpg)

It can be noticed from the above algorithm that the generator and discriminator are trained separately. In the first section, real data and fake data are inserted into the discriminator with correct labels and training takes place. Gradients are propagated keeping generator fixed. Also, we update the discriminator by ascending its stochastic gradient because for discriminator we want to maximize the loss function given in equation (6).
On the other hand, we update the generator by keeping discriminator fixed and passing fake data with fake labels in order to fool the discriminator. Here, we update the generator by descending its stochastic gradient because for the generator we want to minimize the loss function given in equation (6).

#### Generated by mnist dcgan

![dcgan (1)](https://user-images.githubusercontent.com/50628520/90311344-b90c7800-df19-11ea-8131-2fbaf307620f.gif)

#### Generated by anime dcgan

![animedcgan](https://user-images.githubusercontent.com/50628520/90311410-510a6180-df1a-11ea-9097-b328d3881360.gif)



## How to train a GAN ? Tips and tricks to make GAN training stable.

### 1) Normalize the inputs:

- Normalize the images between -1 and 1.
- Use `tanh` activation function in the last layer of generator.

### 2) Loss function:

In GAN papers, the loss function to optimize G is `min (log 1-D)`, but in practice folks practically use `max log D`

- because the first formulation has vanishing gradients early on
- Goodfellow et. al (2014)

In practice, works well:

- Flip labels when training generator: real = fake, fake = real

### 3) Use a spherical Z:

- Dont sample from a Uniform distribution
- When doing interpolations, do the interpolation via a great circle, rather than a straight line from point A to point B
- Tom White's [Sampling Generative Networks](https://arxiv.org/abs/1609.04468) ref code https://github.com/dribnet/plat has more details

### 4) Batch Normalization:

- Construct different mini-batches for real and fake, i.e. each mini-batch needs to contain only all real images or all generated images.
- when batchnorm is not an option use instance normalization (for each sample, subtract mean and divide by standard deviation).

### 5) Avoid Sparse Gradients: ReLU, MaxPool

- the stability of the GAN game suffers if you have sparse gradients
- LeakyReLU = good (in both G and D)
- For Downsampling, use: Average Pooling, Conv2d + stride
- For Upsampling, use: PixelShuffle, ConvTranspose2d + stride
  - PixelShuffle: https://arxiv.org/abs/1609.05158

### 6) Use Soft and Noisy labels

- Label Smoothing, i.e. if you have two target labels: Real=1 and Fake=0, then for each incoming sample, if it is real, then replace the label with a random number between 0.7 and 1.2, and if it is a fake sample, replace it with 0.0 and 0.3 (for example).
  - Salimans et. al. 2016
- make the labels the noisy for the discriminator: occasionally flip the labels when training the discriminator
- fake_labels = `tf.random.uniform(shape=[25, 1], minval=0, maxval=0.3, dtype=tf.float32)`
- real_labels = `tf.random.uniform(shape=[25, 1], minval=0.7, maxval=1.2, dtype=tf.float32)`

### 7) Use stability tricks from RL

- Experience Replay
  - Keep a replay buffer of past generations and occassionally show them
  - Keep checkpoints from the past of G and D and occassionaly swap them out for a few iterations
- All stability tricks that work for deep deterministic policy gradients

### 8) Use the ADAM Optimizer

- optim.Adam rules!
  - See Radford et. al. 2015
- Use SGD for discriminator and ADAM for generator

### 9) Track failures early

- D loss goes to 0: failure mode
- check norms of gradients: if they are over 100 things are screwing up
- when things are working, D loss has low variance and goes down over time vs having huge variance and spiking
- if loss of generator steadily decreases, then it's fooling D with garbage (says martin)

### 10) Add noise to inputs, decay over time

- Add some artificial noise to inputs to D (Arjovsky et. al., Huszar, 2016)
  - http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/
  - https://openreview.net/forum?id=Hk4_qw5xe
- adding gaussian noise to every layer of generator (Zhao et. al. EBGAN)
  - Improved GANs: OpenAI code also has it (commented out)

### 11) Use Dropouts in G in both train and test phase

- Provide noise in the form of dropout (50%).
- Apply on several layers of our generator at both training and test time
- https://arxiv.org/pdf/1611.07004v1.pdf